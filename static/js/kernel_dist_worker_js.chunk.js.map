{"version":3,"file":"static/js/kernel_dist_worker_js.chunk.js","mappings":";;;;;;;;;;;;;;;;;;;;AAAA;AAGA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;;AAGA;AACA;AACA;AACA;AACA;;;AAGA;AAEA;AAMA;AACA;AACA;AAEA;AAKA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9CA;AACA;;;;;;;;;;;;;;;;AAgBA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;;AAIA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChBA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AAOA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;;;;;;;;;AASA;;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAGA;AAEA;AACA;AAKA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;;;;AAIA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;;AAGA;AACA;AACA;;;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AAEA;AACA;AACA;AACA;AACA;;;;;;;;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;AAsBA;AACA;AAEA;AAGA;AACA;AACA;;;;;;;AAOA;AACA;AAEA;AACA;AACA;AACA;;;;;;;;;;AAUA;;;;;;;;AAQA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;;;;;AAKA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;AAGA;;;;AAKA;AACA;AACA;AACA;;AAGA;AAEA;AAEA;AACA;AACA;AAAA;AACA;AAEA;AAAA;AAAA;AAEA;AAGA;AAEA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AAGA;AACA;AACA;AACA;;AAEA;AAAA;AACA;AAEA;AAAA;AAAA;AAEA;AACA;;AAEA;AAAA;AACA;AAEA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AAEA;AAOA;;AAEA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAAA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAAA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAAA;AACA;AAAA;AAAA;AAEA;AAEA;AACA;AACA;AAAA;AAEA;AACA;;;AAGA;;AAEA;AAEA;AACA;AACA;AACA;AACA;;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;;;;;;;;;;;;;;;;;;;;ACtcA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACRA;AACA;AACA;AACA;AACA;;;;;ACJA;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACNA;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACpCA;AACA;AACA;AACA;;;;;AEHA;AACA;AACA","sources":["/home/runner/work/stlite-dev/stlite-dev/packages/kernel/src/file.ts","/home/runner/work/stlite-dev/stlite-dev/packages/kernel/src/mock.ts","/home/runner/work/stlite-dev/stlite-dev/packages/kernel/src/requirements.ts","/home/runner/work/stlite-dev/stlite-dev/packages/kernel/src/worker.ts","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/bootstrap","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/runtime/chunk loaded","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/runtime/compat get default export","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/runtime/define property getters","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/runtime/ensure chunk","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/runtime/get javascript chunk filename","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/runtime/hasOwnProperty shorthand","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/runtime/make namespace object","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/runtime/publicPath","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/runtime/react refresh","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/runtime/importScripts chunk loading","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/runtime/startup chunk dependencies","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/before-startup","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/startup","/home/runner/work/stlite-dev/stlite-dev/packages/mountable/webpack/after-startup"],"sourcesContent":["import path from \"path-browserify\";\nimport { PyodideInterface } from \"pyodide\";\n\nfunction ensureParent(pyodide: PyodideInterface, filePath: string): void {\n  const normalized = path.normalize(filePath);\n\n  const dirPath = path.dirname(normalized);\n\n  const dirNames = dirPath.split(\"/\");\n\n  const chDirNames: string[] = [];\n  for (const dirName of dirNames) {\n    chDirNames.push(dirName);\n    const dirPath = chDirNames.join(\"/\");\n\n    if (pyodide.FS.analyzePath(dirPath).exists) {\n      if (pyodide.FS.isDir(dirPath)) {\n        throw new Error(`\"${dirPath}\" already exists and is not a directory.`);\n      }\n      continue;\n    }\n\n    try {\n      pyodide.FS.mkdir(dirPath);\n    } catch (err) {\n      console.error(`Failed to create a directory \"${dirPath}\"`);\n      throw err;\n    }\n  }\n}\n\nexport function writeFileWithParents(\n  pyodide: PyodideInterface,\n  filePath: string,\n  data: string | ArrayBufferView,\n  opts?: Record<string, any>\n): void {\n  ensureParent(pyodide, filePath);\n  pyodide.FS.writeFile(filePath, data, opts);\n}\n\nexport function renameWithParents(\n  pyodide: PyodideInterface,\n  oldPath: string,\n  newPath: string\n): void {\n  ensureParent(pyodide, newPath);\n  pyodide.FS.rename(oldPath, newPath);\n}\n","import { PyodideInterface } from \"pyodide\";\n\nexport function mockPyArrow(pyodide: PyodideInterface) {\n  pyodide.runPython(`\nimport micropip\nmicropip.add_mock_package(\n    \"pyarrow\", \"0.0.1\",\n    modules={\n        \"pyarrow\": \"\"\"\n__version__ = '0.0.1'  # TODO: Update when releasing\n\n\nclass Table:\n    @classmethod\n    def from_pandas(*args, **kwargs):\n        raise NotImplementedError(\"stlite is not supporting this method.\")\n\"\"\"\n    }\n)\n`);\n}\n","export function verifyRequirements(requirements: string[]) {\n  requirements.forEach((req) => {\n    let url: URL;\n    try {\n      url = new URL(req);\n    } catch {\n      // `req` is not a URL -> OK\n      return;\n    }\n\n    // Ref: The scheme checker in the micropip implementation is https://github.com/pyodide/micropip/blob/v0.1.0/micropip/_compat_in_pyodide.py#L23-L26\n    if (url.protocol === \"emfs:\" || url.protocol === \"file:\") {\n      throw new Error(\n        `\"emfs:\" and \"file:\" protocols are not allowed for the requirement (${req})`\n      );\n    }\n  });\n}\n","import { PyodideInterface } from \"pyodide\";\nimport { PromiseDelegate } from \"@lumino/coreutils\";\nimport { writeFileWithParents, renameWithParents } from \"./file\";\nimport { verifyRequirements } from \"./requirements\";\nimport { mockPyArrow } from \"./mock\";\n\nlet pyodide: PyodideInterface;\n\n// Cognite\nlet token: string;\nlet baseUrl: string;\nlet project: string;\n\nlet httpServer: any;\n\ninterface StliteWorkerContext extends Worker {\n  postMessage(message: OutMessage, transfer: Transferable[]): void;\n  postMessage(message: OutMessage, options?: StructuredSerializeOptions): void;\n}\n\n// Ref: https://v4.webpack.js.org/loaders/worker-loader/#loading-with-worker-loader\nconst ctx: StliteWorkerContext = self as any;\n\nconst initDataPromiseDelegate = new PromiseDelegate<WorkerInitialData>();\n\nfunction postProgressMessage(message: string): void {\n  ctx.postMessage({\n    type: \"event:progress\",\n    data: {\n      message,\n    },\n  });\n}\n\n/**\n * Load Pyodided and initialize the interpreter.\n *\n * NOTE: This implementation is based on JupyterLite@v0.1.0a16.\n *       Since v0.1.0a17, a wrapper around micropip, piplite, has been introduced\n *       and the importing strategy of pyolite and other packages has been changed.\n *       We might need to catch up it.\n *       https://github.com/jupyterlite/jupyterlite/pull/310\n */\nasync function loadPyodideAndPackages() {\n  const {\n    entrypoint,\n    files,\n    requirements,\n    wheels,\n    mountedSitePackagesSnapshotFilePath,\n    pyodideEntrypointUrl,\n  } = await initDataPromiseDelegate.promise;\n\n  postProgressMessage(\"Loading Pyodide.\");\n\n  console.debug(\"Import the entrypoint script.\");\n  importScripts(\n    pyodideEntrypointUrl ??\n      \"https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js\"\n  );\n\n  console.debug(\"Loading Pyodide\");\n  pyodide = await loadPyodide({\n    stderr: console.error,\n  });\n  console.debug(\"Loaded Pyodide\");\n\n  console.debug(\"Patch Cognite\");\n  patchCognite();\n\n  // Mount files\n  postProgressMessage(\"Mounting files.\");\n  Object.keys(files).forEach((path) => {\n    const { data, opts } = files[path];\n\n    console.debug(`Write a file \"${path}\"`);\n    writeFileWithParents(pyodide, path, data, opts);\n  });\n\n  if (mountedSitePackagesSnapshotFilePath) {\n    // Restore the site-packages director(y|ies) from the mounted snapshot file.\n    postProgressMessage(\"Restoring the snapshot.\");\n\n    await pyodide.runPythonAsync(`import tarfile, shutil, site`);\n\n    // Remove \"site-packages\" directories such as '/lib/python3.10/site-packages'\n    // assuming these directories will be extracted from the snapshot archive.\n    await pyodide.runPythonAsync(`\n      site_packages_dirs = site.getsitepackages()\n      for site_packages in site_packages_dirs:\n          shutil.rmtree(site_packages)\n    `);\n    console.debug(`Unarchive ${mountedSitePackagesSnapshotFilePath}`);\n    await pyodide.runPythonAsync(`\n      with tarfile.open(\"${mountedSitePackagesSnapshotFilePath}\", \"r\") as tar_gz_file:\n          tar_gz_file.extractall(\"/\")\n    `);\n    console.debug(\"Restored the snapshot\");\n\n    postProgressMessage(\"Mocking some packages.\");\n    console.debug(\"Mock pyarrow\");\n    mockPyArrow(pyodide);\n    console.debug(\"Mocked pyarrow\");\n  } else if (wheels) {\n    postProgressMessage(\"Installing streamlit and its dependencies.\");\n    console.debug(\"Loading stlite-server, and streamlit\");\n    await pyodide.loadPackage(\"micropip\");\n    const micropip = pyodide.pyimport(\"micropip\");\n    await micropip.install.callKwargs([wheels.stliteServer], {\n      keep_going: true,\n    });\n    await micropip.install.callKwargs([wheels.streamlit], { keep_going: true });\n    console.debug(\"Loaded stlite-server, and streamlit\");\n\n    postProgressMessage(\"Mocking some packages.\");\n    console.debug(\"Mock pyarrow\");\n    mockPyArrow(pyodide);\n    console.debug(\"Mocked pyarrow\");\n\n    postProgressMessage(\"Installing the requirements.\");\n    console.debug(\"Installing the requirements:\", requirements);\n    verifyRequirements(requirements); // Blocks the not allowed wheel URL schemes.\n    await micropip.install.callKwargs(requirements, { keep_going: true });\n    console.debug(\"Installed the requirements:\", requirements);\n  } else {\n    throw new Error(`Neither snapshot nor wheel files are provided.`);\n  }\n\n  // The following code is necessary to avoid errors like  `NameError: name '_imp' is not defined`\n  // at importing installed packages.\n  await pyodide.runPythonAsync(`\n    import importlib\n    importlib.invalidate_caches()\n  `);\n\n  postProgressMessage(\"Loading streamlit package.\");\n  console.debug(\"Loading the Streamlit package\");\n  // Importing the `streamlit` module takes most of the time,\n  // so we first run this step independently for clearer logs and easy exec-time profiling.\n  // For https://github.com/whitphx/stlite/issues/427\n  await pyodide.runPythonAsync(`\n      import streamlit.runtime\n      import streamlit.web\n  `);\n  console.debug(\"Loaded the Streamlit package\");\n\n  postProgressMessage(\"Setting up the loggers.\");\n  console.debug(\"Setting the loggers\");\n  // Fix the Streamlit's logger instantiating strategy, which violates the standard and is problematic for us.\n  // See https://github.com/streamlit/streamlit/issues/4742\n  await pyodide.runPythonAsync(`\n      import logging\n      import streamlit.logger\n\n      streamlit.logger.get_logger = logging.getLogger\n      streamlit.logger.setup_formatter = None\n      streamlit.logger.update_formatter = lambda *a, **k: None\n      streamlit.logger.set_log_level = lambda *a, **k: None\n  `);\n  // Then configure the logger.\n  const logCallback = (msg: string) => {\n    if (msg.startsWith(\"CRITICAL\") || msg.startsWith(\"ERROR\")) {\n      console.error(msg);\n    } else if (msg.startsWith(\"WARNING\")) {\n      console.warn(msg);\n    } else if (msg.startsWith(\"INFO\")) {\n      console.info(msg);\n    } else if (msg.startsWith(\"DEBUG\")) {\n      console.debug(msg);\n    } else {\n    }\n  };\n  self.__logCallback__ = logCallback;\n  await pyodide.runPythonAsync(`\n      from js import __logCallback__\n\n\n      class JsHandler(logging.Handler):\n          def emit(self, record):\n              msg = self.format(record)\n              __logCallback__(msg)\n\n\n      main_formatter = logging.Formatter(\"%(levelname)s:%(name)s:%(message)s\")\n\n      js_handler = JsHandler()\n      js_handler.setFormatter(main_formatter)\n\n      root_logger = logging.getLogger()\n      root_logger.handlers.clear()\n      root_logger.addHandler(js_handler)\n      root_logger.setLevel(logging.DEBUG)\n\n      streamlit_handler = logging.getLogger(\"streamlit\")\n      streamlit_handler.setLevel(logging.DEBUG)\n  `);\n  console.debug(\"Set the loggers\");\n\n  postProgressMessage(\n    \"Mocking some Streamlit functions for the browser environment.\"\n  );\n  console.debug(\"Mocking some Streamlit functions\");\n  // Disable caching. See https://github.com/whitphx/stlite/issues/495\n  await pyodide.runPythonAsync(`\n    import streamlit\n\n    def is_cacheable_msg(msg):\n        return False\n\n    streamlit.runtime.runtime.is_cacheable_msg = is_cacheable_msg\n  `);\n  console.debug(\"Mocked some Streamlit functions\");\n\n  postProgressMessage(\"Booting up the Streamlit server.\");\n  console.debug(\"Booting up the Streamlit server\");\n  // The following Python code is based on streamlit.web.cli.main_run().\n  await pyodide.runPythonAsync(`\n    from stlite_server.bootstrap import load_config_options, prepare\n    from stlite_server.server import Server\n\n    load_config_options({\n        \"global.dataFrameSerialization\": \"legacy\",  # Not to use PyArrow\n        \"browser.gatherUsageStats\": False,\n        \"runner.fastReruns\": False,  # Fast reruns do not work well with the async script runner of stlite. See https://github.com/whitphx/stlite/pull/550#issuecomment-1505485865.\n    })\n\n    main_script_path = \"${entrypoint}\"\n    command_line = None\n    args = []\n\n    prepare(main_script_path, args)\n\n    server = Server(main_script_path, command_line)\n    server.start()\n  `);\n  console.debug(\"Booted up the Streamlit server\");\n\n  console.debug(\"Setting up the HTTP server\");\n  // Pull the http server instance from Python world to JS world and set up it.\n  httpServer = pyodide.globals.get(\"server\").copy();\n  console.debug(\"Set up the HTTP server\");\n\n  ctx.postMessage({\n    type: \"event:loaded\",\n  });\n}\n\nconst pyodideReadyPromise = loadPyodideAndPackages().catch((error) => {\n  ctx.postMessage({\n    type: \"event:error\",\n    data: {\n      error,\n    },\n  });\n  throw error;\n});\n\n/**\n * Process a message sent to the worker.\n *\n * @param event The message event to process\n */\nself.onmessage = async (event: MessageEvent<InMessage>): Promise<void> => {\n  const data = event.data;\n\n  // handle Cognite data\n  if (event.data.type === \"newToken\") {\n    token = data.token;\n    project = data.project;\n    baseUrl = data.baseUrl;\n\n    if (token && project && baseUrl) {\n      if (pyodide) {\n        // If kernel is ready, set new values\n        await pyodide.runPythonAsync(`\n        import os\n        os.environ[\"COGNITE_TOKEN\"] = \"${token}\"\n        os.environ[\"COGNITE_PROJECT\"] = \"${project}\"\n        os.environ[\"COGNITE_BASE_URL\"] = \"${baseUrl}\"\n        # Set flag to tell the SDK that we are inside of a Fusion Notebook:\n        os.environ[\"COGNITE_FUSION_NOTEBOOK\"] = \"1\"\n      `);\n      }\n    }\n  }\n\n  // Special case for transmitting the initial data\n  if (data.type === \"initData\") {\n    initDataPromiseDelegate.resolve(data.data);\n    return;\n  }\n\n  await pyodideReadyPromise;\n\n  const messagePort = event.ports[0];\n\n  try {\n    switch (data.type) {\n      case \"websocket:connect\": {\n        console.debug(\"websocket:connect\", data.data);\n\n        const { path } = data.data;\n\n        httpServer.start_websocket(\n          path,\n          (messageProxy: any, binary: boolean) => {\n            // XXX: Now there is no session mechanism\n\n            if (binary) {\n              const buffer = messageProxy.getBuffer(\"u8\");\n              messageProxy.destroy();\n              const payload = new Uint8ClampedArray(\n                buffer.data.buffer,\n                buffer.data.byteOffset,\n                buffer.data.byteLength\n              );\n              ctx.postMessage({\n                type: \"websocket:message\",\n                data: {\n                  payload: new Uint8Array(payload),\n                },\n              });\n            } else {\n              ctx.postMessage({\n                type: \"websocket:message\",\n                data: {\n                  payload: messageProxy,\n                },\n              });\n            }\n          }\n        );\n\n        messagePort.postMessage({\n          type: \"reply\",\n        });\n        break;\n      }\n      case \"websocket:send\": {\n        console.debug(\"websocket:send\", data.data);\n\n        const { payload } = data.data;\n\n        httpServer.receive_websocket_from_js(payload);\n        break;\n      }\n      case \"http:request\": {\n        console.debug(\"http:request\", data.data);\n\n        const { request } = data.data;\n\n        const onResponse = (statusCode: number, _headers: any, _body: any) => {\n          const headers = _headers.toJs();\n          const body = _body.toJs();\n          console.debug({ statusCode, headers, body });\n\n          const reply: HttpResponseMessage = {\n            type: \"http:response\",\n            data: {\n              response: {\n                statusCode,\n                headers,\n                body,\n              },\n            },\n          };\n          messagePort.postMessage(reply);\n        };\n\n        httpServer.receive_http_from_js(\n          request.method,\n          request.path,\n          request.headers,\n          request.body,\n          onResponse\n        );\n        break;\n      }\n      case \"file:write\": {\n        const { path, data: fileData, opts } = data.data;\n\n        console.debug(`Write a file \"${path}\"`);\n        writeFileWithParents(pyodide, path, fileData, opts);\n        messagePort.postMessage({\n          type: \"reply\",\n        });\n        break;\n      }\n      case \"file:rename\": {\n        const { oldPath, newPath } = data.data;\n\n        console.debug(`Rename \"${oldPath}\" to ${newPath}`);\n        renameWithParents(pyodide, oldPath, newPath);\n        messagePort.postMessage({\n          type: \"reply\",\n        });\n        break;\n      }\n      case \"file:unlink\": {\n        const { path } = data.data;\n\n        console.debug(`Remove \"${path}`);\n        pyodide.FS.unlink(path);\n        messagePort.postMessage({\n          type: \"reply\",\n        });\n        break;\n      }\n      case \"install\": {\n        const { requirements } = data.data;\n\n        const micropip = pyodide.pyimport(\"micropip\");\n\n        verifyRequirements(requirements); // Blocks the not allowed wheel URL schemes.\n        await micropip.install\n          .callKwargs(requirements, { keep_going: true })\n          .then(() => {\n            if (requirements.includes(\"matplotlib\")) {\n              return pyodide.runPythonAsync(`\n                from stlite_server.bootstrap import _fix_matplotlib_crash\n                _fix_matplotlib_crash()\n              `);\n            }\n          })\n          .then(() => {\n            console.debug(\"Successfully installed\");\n            messagePort.postMessage({\n              type: \"reply\",\n            });\n          });\n      }\n    }\n  } catch (error) {\n    messagePort.postMessage({\n      type: \"reply\",\n      error,\n    });\n  }\n};\n\nctx.postMessage({\n  type: \"event:start\",\n});\n\nconst patchCognite = async (): Promise<void> => {\n  // If token has been passed already, set token etc\n  await pyodide.runPythonAsync(`\n    import os\n    os.environ[\"COGNITE_TOKEN\"] = \"${token}\"\n    os.environ[\"COGNITE_PROJECT\"] = \"${project}\"\n    os.environ[\"COGNITE_BASE_URL\"] = \"${baseUrl}\"\n    # Set flag to tell the SDK that we are inside of a Fusion Notebook:\n    os.environ[\"COGNITE_FUSION_NOTEBOOK\"] = \"1\"\n  `);\n};\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\tvar execOptions = { id: moduleId, module: module, factory: __webpack_modules__[moduleId], require: __webpack_require__ };\n\t__webpack_require__.i.forEach(function(handler) { handler(execOptions); });\n\tmodule = execOptions.module;\n\texecOptions.factory.call(module.exports, module, module.exports, execOptions.require);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n// expose the module cache\n__webpack_require__.c = __webpack_module_cache__;\n\n// expose the module execution interceptor\n__webpack_require__.i = [];\n\n// the startup function\n__webpack_require__.x = () => {\n\t// Load entry module and return exports\n\tvar __webpack_exports__ = __webpack_require__.O(undefined, [\"vendors-node_modules_lumino_coreutils_dist_index_es6_js-node_modules_pmmmwh_react-refresh-web-3315f5\"], () => (__webpack_require__(\"../kernel/dist/worker.js\")))\n\t__webpack_exports__ = __webpack_require__.O(__webpack_exports__);\n\treturn __webpack_exports__;\n};\n\n","var deferred = [];\n__webpack_require__.O = (result, chunkIds, fn, priority) => {\n\tif(chunkIds) {\n\t\tpriority = priority || 0;\n\t\tfor(var i = deferred.length; i > 0 && deferred[i - 1][2] > priority; i--) deferred[i] = deferred[i - 1];\n\t\tdeferred[i] = [chunkIds, fn, priority];\n\t\treturn;\n\t}\n\tvar notFulfilled = Infinity;\n\tfor (var i = 0; i < deferred.length; i++) {\n\t\tvar [chunkIds, fn, priority] = deferred[i];\n\t\tvar fulfilled = true;\n\t\tfor (var j = 0; j < chunkIds.length; j++) {\n\t\t\tif ((priority & 1 === 0 || notFulfilled >= priority) && Object.keys(__webpack_require__.O).every((key) => (__webpack_require__.O[key](chunkIds[j])))) {\n\t\t\t\tchunkIds.splice(j--, 1);\n\t\t\t} else {\n\t\t\t\tfulfilled = false;\n\t\t\t\tif(priority < notFulfilled) notFulfilled = priority;\n\t\t\t}\n\t\t}\n\t\tif(fulfilled) {\n\t\t\tdeferred.splice(i--, 1)\n\t\t\tvar r = fn();\n\t\t\tif (r !== undefined) result = r;\n\t\t}\n\t}\n\treturn result;\n};","// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = (module) => {\n\tvar getter = module && module.__esModule ?\n\t\t() => (module['default']) :\n\t\t() => (module);\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.f = {};\n// This file contains only the entry chunk.\n// The chunk loading function for additional chunks\n__webpack_require__.e = (chunkId) => {\n\treturn Promise.all(Object.keys(__webpack_require__.f).reduce((promises, key) => {\n\t\t__webpack_require__.f[key](chunkId, promises);\n\t\treturn promises;\n\t}, []));\n};","// This function allow to reference async chunks and sibling chunks for the entrypoint\n__webpack_require__.u = (chunkId) => {\n\t// return url for filenames based on template\n\treturn \"static/js/\" + chunkId + \".chunk.js\";\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","__webpack_require__.p = \"/stlite/\";","__webpack_require__.i.push((options) => {\n\tconst originalFactory = options.factory;\n\toptions.factory = function (moduleObject, moduleExports, webpackRequire) {\n\t\t__webpack_require__.$Refresh$.setup(options.id);\n\t\ttry {\n\t\t\toriginalFactory.call(this, moduleObject, moduleExports, webpackRequire);\n\t\t} finally {\n\t\t\tif (typeof Promise !== 'undefined' && moduleObject.exports instanceof Promise) {\n\t\t\t\toptions.module.exports = options.module.exports.then(\n\t\t\t\t\t(result) => {\n\t\t\t\t\t\t__webpack_require__.$Refresh$.cleanup(options.id);\n\t\t\t\t\t\treturn result;\n\t\t\t\t\t},\n\t\t\t\t\t(reason) => {\n\t\t\t\t\t\t__webpack_require__.$Refresh$.cleanup(options.id);\n\t\t\t\t\t\treturn Promise.reject(reason);\n\t\t\t\t\t}\n\t\t\t\t);\n\t\t\t} else {\n\t\t\t\t__webpack_require__.$Refresh$.cleanup(options.id)\n\t\t\t}\n\t\t}\n\t};\n})\n\n__webpack_require__.$Refresh$ = {\n\tregister: () => (undefined),\n\tsignature: () => ((type) => (type)),\n\truntime: {\n\t\tcreateSignatureFunctionForTransform: () => ((type) => (type)),\n\t\tregister: () => (undefined)\n\t},\n\tsetup: (currentModuleId) => {\n\t\tconst prevModuleId = __webpack_require__.$Refresh$.moduleId;\n\t\tconst prevRegister = __webpack_require__.$Refresh$.register;\n\t\tconst prevSignature = __webpack_require__.$Refresh$.signature;\n\t\tconst prevCleanup = __webpack_require__.$Refresh$.cleanup;\n\n\t\t__webpack_require__.$Refresh$.moduleId = currentModuleId;\n\n\t\t__webpack_require__.$Refresh$.register = (type, id) => {\n\t\t\tconst typeId = currentModuleId + \" \" + id;\n\t\t\t__webpack_require__.$Refresh$.runtime.register(type, typeId);\n\t\t}\n\n\t\t__webpack_require__.$Refresh$.signature = () => (__webpack_require__.$Refresh$.runtime.createSignatureFunctionForTransform());\n\n\t\t__webpack_require__.$Refresh$.cleanup = (cleanupModuleId) => {\n\t\t\tif (currentModuleId === cleanupModuleId) {\n\t\t\t\t__webpack_require__.$Refresh$.moduleId = prevModuleId;\n\t\t\t\t__webpack_require__.$Refresh$.register = prevRegister;\n\t\t\t\t__webpack_require__.$Refresh$.signature = prevSignature;\n\t\t\t\t__webpack_require__.$Refresh$.cleanup = prevCleanup;\n\t\t\t}\n\t\t}\n\t}\n};","// no baseURI\n\n// object to store loaded chunks\n// \"1\" means \"already loaded\"\nvar installedChunks = {\n\t\"kernel_dist_worker_js\": 1\n};\n\n// importScripts chunk loading\nvar installChunk = (data) => {\n\tvar [chunkIds, moreModules, runtime] = data;\n\tfor(var moduleId in moreModules) {\n\t\tif(__webpack_require__.o(moreModules, moduleId)) {\n\t\t\t__webpack_require__.m[moduleId] = moreModules[moduleId];\n\t\t}\n\t}\n\tif(runtime) runtime(__webpack_require__);\n\twhile(chunkIds.length)\n\t\tinstalledChunks[chunkIds.pop()] = 1;\n\tparentChunkLoadingFunction(data);\n};\n__webpack_require__.f.i = (chunkId, promises) => {\n\t// \"1\" is the signal for \"already loaded\"\n\tif(!installedChunks[chunkId]) {\n\t\tif(true) { // all chunks have JS\n\t\t\timportScripts(__webpack_require__.p + __webpack_require__.u(chunkId));\n\t\t}\n\t}\n};\n\nvar chunkLoadingGlobal = globalThis[\"webpackChunk_stlite_mountable\"] = globalThis[\"webpackChunk_stlite_mountable\"] || [];\nvar parentChunkLoadingFunction = chunkLoadingGlobal.push.bind(chunkLoadingGlobal);\nchunkLoadingGlobal.push = installChunk;\n\n// no HMR\n\n// no HMR manifest","var next = __webpack_require__.x;\n__webpack_require__.x = () => {\n\treturn __webpack_require__.e(\"vendors-node_modules_lumino_coreutils_dist_index_es6_js-node_modules_pmmmwh_react-refresh-web-3315f5\").then(next);\n};","","// module cache are used so entry inlining is disabled\n// run startup\nvar __webpack_exports__ = __webpack_require__.x();\n",""],"names":[],"sourceRoot":""}